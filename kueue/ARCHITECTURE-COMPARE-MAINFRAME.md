# Kueue vs Mainframe Batch Systems - Architecture Comparison

## Executive Summary

**"The best ideas never dieâ€”they get modernized and adapted to new platforms!"**

This document compares Kueue with mainframe batch systems to help understand the architectural parallels.

---

## Side-by-Side Comparison

| **Mainframe Concept** | **Kueue Equivalent** | **Purpose** |
|----------------------|---------------------|-------------|
| **JES2/JES3** | **Kueue Controller** | Job queue management and scheduling |
| **Job Class** | **LocalQueue + WorkloadPriorityClass** | Job categorization and routing |
| **Initiator** | **Kubernetes Scheduler** | Executes jobs when resources available |
| **Service Class** | **ClusterQueue** | Resource pool with guaranteed resources |
| **WLM (Workload Manager)** | **ClusterQueue + Cohort** | Dynamic resource allocation and priorities |
| **SYSOUT Class** | *N/A (handled by logging)* | Output management |
| **JCL (Job Control Language)** | **Job YAML + Labels** | Job definition and requirements |
| **Job Entry** | **Job Submission (kubectl apply)** | How jobs enter the system |
| **Job Queue** | **Workload Queue** | Jobs waiting for resources |
| **Performance Group** | **ResourceFlavor + NodeSelector** | Resource characteristics/partitioning |
| **Goal Mode** | **QueueingStrategy + Preemption** | Response time and throughput goals |
| **Resource Group** | **ResourceGroup in ClusterQueue** | Grouping resources (CPU, memory, etc.) |
| **SMF Records** | **Prometheus Metrics** | Job accounting and monitoring |
| **RACF/Security** | **RBAC + Namespaces** | Access control and isolation |
| **LPAR** | **Kubernetes Node/Node Pool** | Physical/logical resource partitioning |
| **Parallel Sysplex** | **Multi-cluster (MultiKueue)** | Multiple systems sharing workload |

---

## Detailed Architectural Comparison

### 1. Job Entry Subsystem (JES2/JES3) â†” Kueue Controller

#### **Mainframe: JES2/JES3**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            JES2/JES3                        â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Job Entry                          â”‚   â”‚
â”‚  â”‚  â€¢ Accepts jobs via internal reader â”‚   â”‚
â”‚  â”‚  â€¢ Validates JCL                    â”‚   â”‚
â”‚  â”‚  â€¢ Assigns job number (JOBxxxxx)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Job Queue Management               â”‚   â”‚
â”‚  â”‚  â€¢ Queues by CLASS                  â”‚   â”‚
â”‚  â”‚  â€¢ Priority ordering                â”‚   â”‚
â”‚  â”‚  â€¢ Holds and releases               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Job Selection                      â”‚   â”‚
â”‚  â”‚  â€¢ Matches to initiators            â”‚   â”‚
â”‚  â”‚  â€¢ Checks resource availability     â”‚   â”‚
â”‚  â”‚  â€¢ Submits to execution             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **Kueue: Controller**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Kueue Controller                    â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Job Watcher                        â”‚   â”‚
â”‚  â”‚  â€¢ Watches for new Jobs             â”‚   â”‚
â”‚  â”‚  â€¢ Validates queue labels           â”‚   â”‚
â”‚  â”‚  â€¢ Creates Workload object          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Queue Management                   â”‚   â”‚
â”‚  â”‚  â€¢ Queues in LocalQueue             â”‚   â”‚
â”‚  â”‚  â€¢ Priority ordering                â”‚   â”‚
â”‚  â”‚  â€¢ Suspend/Unsuspend control        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Admission Control                  â”‚   â”‚
â”‚  â”‚  â€¢ Checks ClusterQueue quota        â”‚   â”‚
â”‚  â”‚  â€¢ Reserves resources               â”‚   â”‚
â”‚  â”‚  â€¢ Unsuspends job for execution     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Similarities:**
- Both accept jobs into a managed queue
- Both validate job definitions before queuing
- Both perform admission control based on resources
- Both track job lifecycle from submission to completion

---

### 2. Job Class â†” LocalQueue + Priority

#### **Mainframe: Job Class**
```jcl
//PAYROLL  JOB (ACCT123),'WEEKLY PAYROLL',
//         CLASS=A,              â† High priority production
//         MSGCLASS=X,
//         MSGLEVEL=(1,1),
//         TIME=10,
//         REGION=4M

//BACKUP   JOB (ACCT456),'NIGHTLY BACKUP',
//         CLASS=B,              â† Lower priority batch
//         MSGCLASS=X,
//         TIME=120

//DEVTEST  JOB (ACCT789),'DEV TESTING',
//         CLASS=C,              â† Development/test work
//         MSGCLASS=X,
//         TIME=5
```

**Classes Define:**
- Priority (A > B > C)
- Resource allocation
- Which initiators can run them
- Scheduling preference

#### **Kueue: LocalQueue + Priority**
```yaml
# High priority production
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    kueue.x-k8s.io/queue-name: production-queue
    kueue.x-k8s.io/priority-class: high-priority
spec:
  parallelism: 10
  template:
    spec:
      containers:
      - name: payroll
        resources:
          requests:
            cpu: "2"
            memory: "4Gi"

---
# Lower priority batch
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    kueue.x-k8s.io/queue-name: batch-queue
    kueue.x-k8s.io/priority-class: medium-priority
spec:
  parallelism: 5
  template:
    spec:
      containers:
      - name: backup

---
# Development/test
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    kueue.x-k8s.io/queue-name: dev-queue
    kueue.x-k8s.io/priority-class: low-priority
```

**Parallel Concepts:**
- LocalQueue = Job Class routing
- WorkloadPriorityClass = Job CLASS priority
- Namespace = Accounting/project separation
- Labels = Job categorization

---

### 3. Initiator â†” Kubernetes Scheduler

#### **Mainframe: Initiator**
```
Initiator Configuration:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INIT1: CLASS=(A,B), PRTY=15           â”‚
â”‚   Can run CLASS A or B jobs            â”‚
â”‚   High priority initiator              â”‚
â”‚                                        â”‚
â”‚ INIT2: CLASS=(B,C), PRTY=10           â”‚
â”‚   Can run CLASS B or C jobs            â”‚
â”‚   Medium priority                      â”‚
â”‚                                        â”‚
â”‚ INIT3: CLASS=(C), PRTY=5              â”‚
â”‚   Can only run CLASS C jobs            â”‚
â”‚   Low priority                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Function:
â€¢ Waits for jobs in assigned classes
â€¢ Claims job when available
â€¢ Allocates resources (memory, devices)
â€¢ Starts job execution
â€¢ Monitors completion
â€¢ Releases resources
```

#### **Kueue: Kubernetes Scheduler (Post-Admission)**
```
Kueue Flow:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Job submitted (suspended)           â”‚
â”‚ 2. Kueue checks ClusterQueue quota     â”‚
â”‚ 3. If quota available:                 â”‚
â”‚    - Workload marked "Admitted"        â”‚
â”‚    - Quota reserved                    â”‚
â”‚    - Job unsuspended                   â”‚
â”‚ 4. Kubernetes Scheduler:               â”‚
â”‚    - Selects appropriate node          â”‚
â”‚    - Checks node capacity              â”‚
â”‚    - Binds pod to node                 â”‚
â”‚    - Kubelet starts container          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Key Difference:
â€¢ Kueue = Admission control (can it run?)
â€¢ K8s Scheduler = Placement (where to run?)
â€¢ Similar to JES2 + Initiator combined
```

**Parallel:**
- Initiator "claims" jobs â†’ Kueue "admits" workloads
- Initiator checks resources â†’ ClusterQueue checks quota
- Initiator starts execution â†’ Scheduler places pods
- Both manage job lifecycle

---

### 4. Workload Manager (WLM) â†” ClusterQueue + Cohort

#### **Mainframe: WLM (Workload Manager)**

```
Service Classes and Goals:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Service Class: PROD                          â”‚
â”‚   Goal: 90% complete within 5 seconds        â”‚
â”‚   Importance: 1 (highest)                    â”‚
â”‚   Resources: Can use up to 80% CPU           â”‚
â”‚                                              â”‚
â”‚ Service Class: BATCH                         â”‚
â”‚   Goal: Discretionary (use leftover)        â”‚
â”‚   Importance: 3                              â”‚
â”‚   Resources: Can use remaining CPU           â”‚
â”‚                                              â”‚
â”‚ Service Class: DEV                           â”‚
â”‚   Goal: Velocity (throughput)               â”‚
â”‚   Importance: 4 (lowest)                     â”‚
â”‚   Resources: Minimum 10% CPU guaranteed      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

WLM Behavior:
â€¢ Monitors service class performance vs goals
â€¢ Adjusts dispatching priorities dynamically
â€¢ Moves resources between service classes
â€¢ Preempts lower importance work when needed
â€¢ Reports performance against goals
```

#### **Kueue: ClusterQueue + Cohort**

```yaml
# Production ClusterQueue (like PROD service class)
apiVersion: kueue.x-k8s.io/v1beta1
kind: ClusterQueue
metadata:
  name: production-cq
spec:
  cohort: company-wide  # Can borrow/lend resources
  preemption:
    withinClusterQueue: LowerPriority
    reclaimWithinCohort: Any
    borrowWithinCohort:
      policy: LowerPriority
  resourceGroups:
  - coveredResources: ["cpu", "memory"]
    flavors:
    - name: default-flavor
      resources:
      - name: cpu
        nominalQuota: 50        # Guaranteed: 50 CPUs
        borrowingLimit: 30      # Can borrow: +30 CPUs
      - name: memory
        nominalQuota: 200Gi

---
# Batch ClusterQueue (like BATCH service class)
apiVersion: kueue.x-k8s.io/v1beta1
kind: ClusterQueue
metadata:
  name: batch-cq
spec:
  cohort: company-wide
  preemption:
    reclaimWithinCohort: Never  # Can be preempted
  resourceGroups:
  - coveredResources: ["cpu", "memory"]
    flavors:
    - name: default-flavor
      resources:
      - name: cpu
        nominalQuota: 20
        borrowingLimit: 50      # Opportunistic use
        lendingLimit: 15        # Can lend to others

---
# Dev ClusterQueue (like DEV service class)
apiVersion: kueue.x-k8s.io/v1beta1
kind: ClusterQueue
metadata:
  name: dev-cq
spec:
  cohort: company-wide
  resourceGroups:
  - coveredResources: ["cpu", "memory"]
    flavors:
    - name: default-flavor
      resources:
      - name: cpu
        nominalQuota: 10        # Minimum guaranteed
        borrowingLimit: 20
```

**WLM vs Kueue Cohort Behavior:**

| **WLM Feature** | **Kueue Equivalent** | **Behavior** |
|-----------------|---------------------|--------------|
| Service Class | ClusterQueue | Resource pool definition |
| Importance Level | Priority in preemption policy | Determines who gets preempted |
| Resource Groups | Cohort | Share resources across queues |
| Goal Mode | QueueingStrategy | FIFO, priority-based, velocity |
| Dynamic Priority | Preemption + Borrowing | Adjust resource allocation |
| Discretionary | borrowingLimit | Use idle resources |
| Resource Isolation | nominalQuota | Guaranteed minimum |

**Key Similarity:**
Both systems dynamically adjust resource allocation based on:
- Workload demand
- Priority/Importance
- Performance goals
- Available capacity
- Fair sharing policies

---

### 5. Resource Management Comparison

#### **Mainframe: LPAR + WLM**
```
Physical Mainframe (z15)
â”œâ”€â”€ LPAR1 (Production) - 60% CPU weight
â”‚   â”œâ”€â”€ Service Class PROD (Importance 1)
â”‚   â”œâ”€â”€ Service Class BATCH (Importance 3)
â”‚   â””â”€â”€ WLM manages priorities within LPAR
â”‚
â”œâ”€â”€ LPAR2 (Development) - 30% CPU weight
â”‚   â”œâ”€â”€ Service Class DEV (Importance 4)
â”‚   â””â”€â”€ Service Class TEST (Importance 5)
â”‚
â””â”€â”€ LPAR3 (QA) - 10% CPU weight
    â””â”€â”€ Service Class QA (Importance 3)

WLM can:
â€¢ Shift CPU between service classes within LPAR
â€¢ Adjust dispatching priority based on goals
â€¢ Preempt lower importance work
â€¢ Move work between systems (Sysplex)
```

#### **Kueue: Node Pools + ClusterQueues**
```
Kubernetes Cluster
â”œâ”€â”€ Node Pool: Production (60 CPUs)
â”‚   â”œâ”€â”€ ResourceFlavor: prod-flavor
â”‚   â”œâ”€â”€ ClusterQueue: production-cq (nominalQuota: 50 CPU)
â”‚   â”œâ”€â”€ ClusterQueue: batch-cq (nominalQuota: 20 CPU)
â”‚   â””â”€â”€ Cohort manages borrowing/lending
â”‚
â”œâ”€â”€ Node Pool: Development (30 CPUs)
â”‚   â”œâ”€â”€ ResourceFlavor: dev-flavor
â”‚   â””â”€â”€ ClusterQueue: dev-cq (nominalQuota: 30 CPU)
â”‚
â””â”€â”€ Node Pool: QA (10 CPUs)
    â”œâ”€â”€ ResourceFlavor: qa-flavor
    â””â”€â”€ ClusterQueue: qa-cq (nominalQuota: 10 CPU)

Kueue can:
â€¢ Share CPU quota between ClusterQueues via Cohort
â€¢ Adjust admission based on priority
â€¢ Preempt lower priority workloads
â€¢ Distribute work across clusters (MultiKueue)
```

---

### 6. Job Definition Language Comparison

#### **Mainframe: JCL (Job Control Language)**
```jcl
//PAYROLL  JOB (ACCT123),'WEEKLY PAYROLL',
//         CLASS=A,              â† Queue/Priority
//         MSGCLASS=X,
//         MSGLEVEL=(1,1),
//         NOTIFY=&SYSUID,
//         TIME=10,              â† Time limit
//         REGION=4M             â† Memory requirement
//*
//STEP1    EXEC PGM=PAYROLL01,
//         PARM='WEEKLY'
//SYSPRINT DD SYSOUT=*
//PAYFILE  DD DSN=PAY.MASTER.FILE,
//            DISP=SHR
//UPDTFILE DD DSN=PAY.UPDATE.FILE,
//            DISP=(NEW,CATLG),
//            SPACE=(CYL,(10,5)),
//            UNIT=SYSDA
```

#### **Kueue: Kubernetes Job YAML**
```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: payroll
  namespace: finance                          # Like ACCT/USER
  labels:
    kueue.x-k8s.io/queue-name: production-queue  # Like CLASS
    kueue.x-k8s.io/priority-class: high-priority  # Priority
spec:
  activeDeadlineSeconds: 600               # Like TIME=10
  parallelism: 1
  completions: 1
  suspend: true                            # Kueue controls execution
  template:
    spec:
      containers:
      - name: payroll01                    # Like PGM=PAYROLL01
        image: payroll:v1.0
        args: ["--mode=WEEKLY"]            # Like PARM
        resources:
          requests:
            memory: "4Gi"                  # Like REGION=4M
            cpu: "2"
        volumeMounts:
        - name: pay-master
          mountPath: /data/master
        - name: pay-update
          mountPath: /data/update
      volumes:
      - name: pay-master                   # Like DD DSN=PAY.MASTER.FILE
        persistentVolumeClaim:
          claimName: pay-master-pvc
      - name: pay-update                   # Like DD DSN=PAY.UPDATE.FILE
        persistentVolumeClaim:
          claimName: pay-update-pvc
      restartPolicy: Never
```

**Conceptual Mapping:**
- `JOB` statement â†’ Job metadata
- `CLASS` â†’ `kueue.x-k8s.io/queue-name`
- `REGION` â†’ `resources.requests.memory`
- `TIME` â†’ `activeDeadlineSeconds`
- `EXEC PGM` â†’ `container.image`
- `PARM` â†’ `container.args`
- `DD` statement â†’ `volumeMounts` + `volumes`
- `SYSOUT` â†’ stdout/stderr (logging)

---

### 7. Fair Sharing and Priority

#### **Mainframe: WLM Fair Share**
```
Fair Share Configuration:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Report Class: FINANCE                    â”‚
â”‚   Fair Share: 40%                        â”‚
â”‚   Service Classes: PROD, BATCH           â”‚
â”‚                                          â”‚
â”‚ Report Class: MARKETING                  â”‚
â”‚   Fair Share: 30%                        â”‚
â”‚   Service Classes: ANALYTICS             â”‚
â”‚                                          â”‚
â”‚ Report Class: IT                         â”‚
â”‚   Fair Share: 30%                        â”‚
â”‚   Service Classes: DEV, TEST             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

WLM adjusts priorities to meet fair share goals
over time (typically 3-5 minute intervals)
```

#### **Kueue: Fair Sharing**
```yaml
apiVersion: kueue.x-k8s.io/v1beta1
kind: ClusterQueue
metadata:
  name: finance-cq
spec:
  cohort: company-wide
  fairSharing:
    weight: 40                    # Like Fair Share: 40%
  preemption:
    reclaimWithinCohort: Any
    borrowWithinCohort:
      policy: LowerPriority
  resourceGroups:
  - coveredResources: ["cpu", "memory"]
    flavors:
    - name: default-flavor
      resources:
      - name: cpu
        nominalQuota: 40

---
apiVersion: kueue.x-k8s.io/v1beta1
kind: ClusterQueue
metadata:
  name: marketing-cq
spec:
  cohort: company-wide
  fairSharing:
    weight: 30                    # Like Fair Share: 30%
  resourceGroups:
  - coveredResources: ["cpu"]
    flavors:
    - name: default-flavor
      resources:
      - name: cpu
        nominalQuota: 30

---
apiVersion: kueue.x-k8s.io/v1beta1
kind: ClusterQueue
metadata:
  name: it-cq
spec:
  cohort: company-wide
  fairSharing:
    weight: 30
  resourceGroups:
  - coveredResources: ["cpu"]
    flavors:
    - name: default-flavor
      resources:
      - name: cpu
        nominalQuota: 30
```

**Fair Sharing Behavior:**
- Both systems track resource usage over time
- Adjust priorities to meet target allocations
- Allow temporary over/under use
- Reclaim resources when needed
- Preempt to maintain fairness

---

### 8. Parallel Execution and Sysplex

#### **Mainframe: Parallel Sysplex**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Parallel Sysplex                          â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   System A  â”‚  â”‚   System B  â”‚  â”‚   System C  â”‚â”‚
â”‚  â”‚   (z15)     â”‚  â”‚   (z15)     â”‚  â”‚   (z15)     â”‚â”‚
â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚â”‚
â”‚  â”‚ JES2 Member â”‚  â”‚ JES2 Member â”‚  â”‚ JES2 Member â”‚â”‚
â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚         â”‚                â”‚                â”‚        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                          â”‚                         â”‚
â”‚                   Shared Job Queue                 â”‚
â”‚                   Shared Spool                     â”‚
â”‚                   Coupling Facility                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Features:
â€¢ Jobs can run on any system
â€¢ Workload balancing across systems
â€¢ Automatic failover
â€¢ Shared spool and job queue
â€¢ WLM routes work to best system
```

#### **Kueue: MultiKueue (Multi-Cluster)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           MultiKueue Architecture                   â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      Management Cluster (Hub)               â”‚   â”‚
â”‚  â”‚                                             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚  MultiKueueCluster CRDs               â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Cluster-A (us-east)                â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Cluster-B (us-west)                â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Cluster-C (eu-central)             â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â”‚                                             â”‚   â”‚
â”‚  â”‚  MultiKueue Controller:                    â”‚   â”‚
â”‚  â”‚  â€¢ Receives job submissions                â”‚   â”‚
â”‚  â”‚  â€¢ Checks capacity across clusters         â”‚   â”‚
â”‚  â”‚  â€¢ Routes to cluster with resources        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                    â”‚                               â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚       â”‚            â”‚            â”‚                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚Cluster-A â”‚ â”‚Cluster-B â”‚ â”‚Cluster-C â”‚          â”‚
â”‚  â”‚(AKS)     â”‚ â”‚(EKS)     â”‚ â”‚(GKE)     â”‚          â”‚
â”‚  â”‚          â”‚ â”‚          â”‚ â”‚          â”‚          â”‚
â”‚  â”‚ Kueue    â”‚ â”‚ Kueue    â”‚ â”‚ Kueue    â”‚          â”‚
â”‚  â”‚ Worker   â”‚ â”‚ Worker   â”‚ â”‚ Worker   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Features:
â€¢ Jobs submitted to management cluster
â€¢ Routed to worker cluster with capacity
â€¢ Automatic failover between clusters
â€¢ Cross-cloud support (Azure, AWS, GCP)
â€¢ Federated queue management
```

**Parallel Concepts:**
- Sysplex systems â†’ MultiKueue clusters
- JES2 shared queue â†’ Management cluster queue
- WLM routing â†’ MultiKueue admission controller
- Coupling facility â†’ Management cluster coordination
- Automatic workload balancing in both

---

## Key Philosophical Similarities

### 1. **Separation of Admission and Execution**
- **Mainframe**: JES2 admits jobs, Initiators execute them
- **Kueue**: Kueue admits workloads, Kubernetes Scheduler executes them

### 2. **Resource Virtualization**
- **Mainframe**: Service classes define logical resource pools
- **Kueue**: ClusterQueues define logical quota pools

### 3. **Multi-Tenancy**
- **Mainframe**: Job classes, accounting codes, RACF
- **Kueue**: LocalQueues, namespaces, RBAC

### 4. **Fair Sharing Over Time**
- **Mainframe**: WLM tracks usage and adjusts priorities
- **Kueue**: Fair sharing weights in cohorts

### 5. **Priority and Preemption**
- **Mainframe**: Higher importance can preempt lower
- **Kueue**: Higher priority can preempt lower

### 6. **Queueing Discipline**
- **Mainframe**: FIFO within class, priority between classes
- **Kueue**: BestEffortFIFO or StrictFIFO with priorities

### 7. **Resource Borrowing**
- **Mainframe**: Discretionary workload uses idle resources
- **Kueue**: Borrowing within cohort

### 8. **Accounting and Monitoring**
- **Mainframe**: SMF records track everything
- **Kueue**: Prometheus metrics and events

---

## What's Different?

| **Aspect** | **Mainframe** | **Kueue** |
|------------|---------------|-----------|
| **Scale** | Single large system | Distributed microservices |
| **Granularity** | Job steps, heavyweight | Pods, lightweight containers |
| **Elasticity** | Fixed resources (LPAR) | Dynamic scaling (cloud) |
| **Heterogeneity** | Homogeneous processors | Mixed node types (CPU, GPU, spot) |
| **Networking** | Internal channels | Distributed network |
| **Storage** | DASD, tape | Distributed storage (PV, S3) |
| **Language** | JCL (procedural) | YAML (declarative) |
| **Evolution** | 50+ years refinement | Modern cloud-native (5 years) |

---

## Why the Similarity?

### **Proven Batch Processing Principles**

The mainframe solved batch workload management problems **decades ago**:

1. âœ… **Queue jobs when resources exhausted**
   - Don't let jobs fail due to capacity
   - Provide visibility into wait time

2. âœ… **Fair share resources across tenants**
   - Prevent resource hogging
   - Guarantee minimum allocations

3. âœ… **Priority-based scheduling**
   - Critical work gets resources first
   - Preempt lower priority when needed

4. âœ… **Separate logical quota from physical capacity**
   - Prevent oversubscription
   - Enable capacity planning

5. âœ… **Dynamic resource allocation**
   - Adapt to changing workload
   - Maximize utilization

6. âœ… **Multi-system workload distribution**
   - Balance load across systems
   - Provide high availability

### **Cloud-Native Adaptation**

Kueue brings these proven concepts to Kubernetes:
- Modern declarative API (YAML vs JCL)
- Cloud elasticity (scale nodes dynamically)
- Container-based execution
- Open source and extensible
- Multi-cloud and hybrid support

---

## Mainframe Concepts Not (Yet) in Kueue

Some advanced mainframe features that could inspire Kueue enhancements:

| **Mainframe Feature** | **Description** | **Kueue Status** |
|----------------------|-----------------|-----------------|
| **Automatic Service Class Adjustment** | WLM automatically adjusts service class based on performance | âŒ Manual configuration only |
| **Response Time Goals** | "90% of transactions complete in < 2 seconds" | âŒ No goal-based admission |
| **Velocity Goals** | "Maximize throughput" with dynamic priority | âš ï¸ Partial (fairSharing) |
| **Discretionary Goals** | "Use whatever is left over" | âœ… borrowingLimit |
| **Policy-Based Automation** | Automatic policy changes based on time/conditions | âŒ Manual policy updates |
| **Sysplex-wide Enclaves** | CPU reservations across systems | âŒ Single cluster focus |
| **Job Dependencies (JCL COND)** | Wait for previous job completion | âš ï¸ Requires external tool (Argo, Airflow) |
| **Automatic Restart** | System-managed restart on failure | âš ï¸ Kubernetes Job controller |
| **SMF Detailed Accounting** | Every CPU second accounted | âš ï¸ Prometheus metrics (less granular) |

---

## Real-World Example: Side-by-Side

### **Scenario: Run Weekly Payroll (High Priority) and Backups (Low Priority)**

#### **Mainframe Approach**
```jcl
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// High Priority Payroll
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
//PAYROLL  JOB (PROD),'PAYROLL',
//         CLASS=A,              â† Highest priority
//         MSGCLASS=X,
//         TIME=30,
//         REGION=16M
//STEP1    EXEC PGM=PAY001
//SYSPRINT DD SYSOUT=*
//INPUT    DD DSN=PAY.INPUT,DISP=SHR
//OUTPUT   DD DSN=PAY.OUTPUT,DISP=(NEW,CATLG)

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Low Priority Backup
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
//BACKUP   JOB (BATCH),'BACKUP',
//         CLASS=C,              â† Lower priority
//         MSGCLASS=X,
//         TIME=480
//STEP1    EXEC PGM=BACKUP01
//TAPE     DD DSN=BACKUP.TAPE,
//            DISP=(NEW,KEEP),
//            UNIT=TAPE

WLM Behavior:
1. Both jobs submitted
2. PAYROLL (Class A) gets resources first
3. BACKUP (Class C) runs if resources available
4. If PAYROLL submitted while BACKUP running:
   - WLM raises PAYROLL priority
   - Can preempt BACKUP if needed
   - BACKUP re-queued
```

#### **Kueue Approach**
```yaml
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# High Priority Payroll
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
apiVersion: batch/v1
kind: Job
metadata:
  name: payroll
  namespace: finance
  labels:
    kueue.x-k8s.io/queue-name: production-queue
    kueue.x-k8s.io/priority-class: high-priority
spec:
  activeDeadlineSeconds: 1800  # 30 minutes
  suspend: true
  template:
    spec:
      containers:
      - name: payroll
        image: payroll:v1
        resources:
          requests:
            cpu: "4"
            memory: "16Gi"
      restartPolicy: Never

---
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Low Priority Backup
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
apiVersion: batch/v1
kind: Job
metadata:
  name: backup
  namespace: operations
  labels:
    kueue.x-k8s.io/queue-name: batch-queue
    kueue.x-k8s.io/priority-class: low-priority
spec:
  activeDeadlineSeconds: 28800  # 8 hours
  suspend: true
  template:
    spec:
      containers:
      - name: backup
        image: backup:v1
        resources:
          requests:
            cpu: "2"
            memory: "8Gi"
      restartPolicy: Never

---
# ClusterQueue with preemption enabled
apiVersion: kueue.x-k8s.io/v1beta1
kind: ClusterQueue
metadata:
  name: cluster-queue
spec:
  preemption:
    withinClusterQueue: LowerPriority
  resourceGroups:
  - coveredResources: ["cpu", "memory"]
    flavors:
    - name: default-flavor
      resources:
      - name: cpu
        nominalQuota: 10

Kueue Behavior:
1. Both jobs submitted
2. PAYROLL (high-priority) admitted first if quota available
3. BACKUP (low-priority) admitted if remaining quota
4. If PAYROLL submitted while BACKUP running and no quota:
   - Kueue preempts BACKUP (deletes pods)
   - PAYROLL admitted immediately
   - BACKUP re-queued
```

**Result: Nearly Identical Behavior!**

---

## Conclusion

**Your observation is spot-on!** Kueue is essentially a **cloud-native reimplementation of mainframe batch systems** (JES2/JES3 + WLM) for Kubernetes environments. The architectural patterns, resource management principles, and fair sharing concepts are remarkably similar.

### **Why Reinvent the Wheel?**

The mainframe solved these problems 50+ years ago because they are **fundamental to batch workload management**:
- Limited resources
- Multiple competing users
- Need for fairness
- Priority requirements
- Efficient utilization

### **Modern Context:**

Kueue brings these proven patterns to the **cloud-native world**:
- âœ… Kubernetes-native (YAML, CRDs, controllers)
- âœ… Distributed and scalable
- âœ… Container-based workloads
- âœ… Multi-cloud support
- âœ… Open source
- âœ… Declarative management

### **The Circle of Innovation:**

```
1960s-1970s: Mainframe batch systems invented
             (JES, WLM, job classes, initiators)
                      â†“
2000s-2010s: Cloud computing emerges
             (Initial chaos, no workload management)
                      â†“
2020s:       Kubernetes becomes standard
             (Need batch management again!)
                      â†“
             Kueue: Modern implementation
             of proven mainframe concepts
```

**Lesson:** The best ideas never dieâ€”they get modernized and adapted to new platforms! ğŸ¯

---

## Further Reading

### Mainframe Resources:
- [IBM z/OS JES2 Introduction](https://www.ibm.com/docs/en/zos/2.4.0?topic=introduction-jes2-overview)
- [IBM Workload Manager (WLM)](https://www.ibm.com/docs/en/zos/2.4.0?topic=introduction-workload-manager)
- [JCL Reference](https://www.ibm.com/docs/en/zos/2.4.0?topic=jcl-introduction)

### Kueue Resources:
- [Kueue Official Documentation](https://kueue.sigs.k8s.io/docs/)
- [Kueue GitHub Repository](https://github.com/kubernetes-sigs/kueue)
- [Fair Sharing Concepts](https://kueue.sigs.k8s.io/docs/concepts/fair_sharing/)
- [MultiKueue Architecture](https://kueue.sigs.k8s.io/docs/concepts/multikueue/)
